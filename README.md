# Multiple Personality Chatbot ğŸ¤–ğŸ­

The **Multiple Personality Chatbot** is a modular, LangGraph-powered chatbot system that can dynamically switch between distinct AI personas during live conversations.

* **Factory Method Design** â†’ A `CharacterFactory` generates unique personas with their own behaviors, tone, and quirks.
* **Seamless Personality Switching** â†’ Users can interact with different personalities in real time, without restarting the chatbot.
* **Full-Stack Setup** â†’ Backend (FastAPI) + Frontend (Streamlit) + MongoDB Atlas, all wired together with Docker.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ chatbot-api/            # Backend Service (FastAPI + LangGraph logic)
â”‚   â”œâ”€â”€ src
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ uv.lock
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ .env   (ignored locally)
â”‚
â”œâ”€â”€ chatbot-ui/             # Frontend Service (Streamlit UI)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ uv.lock
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ main.py                 # Entry point for local testing
â”œâ”€â”€ docker-compose.yml      # Runs API + UI together
â””â”€â”€ README.md               # Youâ€™re reading this ğŸ™‚
```

---

## ğŸƒ Quick Start (Docker Compose)

1. **Clone the repository**

   ```bash
   git clone <your_repo_url>
   cd multiple-personality-chatbot
   ```

2. **Configure environment variables**

   * Go to the API folder:

     ```bash
     cd chatbot-api
     cp .env.example .env
     ```
   * Open `.env` and set your **API keys** and **MongoDB Atlas connection URI**.

3. **Return to the root folder**

   ```bash
   cd ..
   ```

4. **Run with Docker Compose**

   ```bash
   docker compose up --build -d
   ```

   * UI â†’ **[http://localhost:8501](http://localhost:8501)**
   * API â†’ **[http://localhost:8000](http://localhost:8000)**

5. **Stop services**

   ```bash
   docker compose down
   ```

âœ… Youâ€™re all set! Your chatbot is live with multiple personalities.

---

## ğŸ—„ Environment Variables

Inside `chatbot-api/.env.example`:

```env
OPENAI_API_KEY="your_openai_key"

MONGO_URI="your_mongo_atlas_uri"
MONGO_DB_NAME=PersonalityChatbot
MONGO_COLLECTION=conversations

LANGSMITH_TRACING="true"
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="your_langsmith_api_key"
LANGSMITH_PROJECT="MultiPersonaChatbot"
```

**Key fields explained:**

* **OPENAI_API_KEY** â†’ Required for LLM calls.
* **MONGO_URI** â†’ MongoDB Atlas connection string.
* **MONGO_DB_NAME / MONGO_COLLECTION** â†’ Storage for chatbot states.
* **LANGSMITH*** â†’ Optional LangSmith tracing & debugging support.

---

## ğŸ›  Development with LangGraph Studio

You can develop/test the chatbot personas directly in [LangGraph Studio](https://www.langchain.com/langgraph):

```bash
cd chatbot-api
langgraph dev --allow-blocking
```

---

## âš™ Manual Setup (No Docker)

### Backend API

```bash
cd chatbot-api
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload
```

### Frontend UI

```bash
cd chatbot-ui
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
streamlit run app.py --server.address 0.0.0.0 --server.port 8501
```

---

## ğŸ³ How Docker Works Here

* **API container** â†’ FastAPI + LangGraph (port `8000`)
* **UI container** â†’ Streamlit frontend (port `8501`)
* Both containers share a Docker network and talk via REST.
* MongoDB Atlas is external (not containerized).

---

## ğŸ”„ Commands Recap

| Action                | Command                                                            |
| --------------------- | ------------------------------------------------------------------ |
| Start Docker services | `docker compose up --build -d`                                     |
| Stop Docker services  | `docker compose down`                                              |
| Run API manually      | `uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload`          |
| Run UI manually       | `streamlit run app.py --server.address 0.0.0.0 --server.port 8501` |
| Run LangGraph Studio  | `langgraph dev --allow-blocking`                                   |

---

## ğŸ­ Why Multiple Personas?

This chatbot isnâ€™t just a single voiceâ€”itâ€™s an ensemble cast. Thanks to the Factory Method, new personalities can be added by simply defining new `Character` classes. Each personality has its own speaking style, quirks, and behavioral logic, making conversations more engaging and flexible.

---
